---
title: "Simple Linear Regression with R"
author: "Karim Lounici"
date: "Fall 2018"
output:
  pdf_document: default
  html_document: default
subtitle: MAP 535-Regression
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

__R__, or rather _the __R__ project for Statistical Computing_, is a Domain Specific Language extremely used in statistics and more generally in data science. . It can be seen an open-source implementation of __S__, a statistical programming language invented in 1976. It is widely used in both the industrial and the academic world. Its main strength is the huge number of packages available while its main drawback is its in-memory processing design which limits the size of the data it can handle. __R__ remains nevertheless a very powerful tools to design a data processing chain.

During the course, we will use __R__ and __Rstudio Desktop__. The first step is thus to install those two programs. They are freely available respectively at https://cran.r-project.org/ and https://www.rstudio.com/products/rstudio/download3/ for windows, OS X and Linux. Be sure to install the latest version of __R__ and of the free version of __Rstudio Desktop__.

We insist on the importance of litterate programming and reproducible research. Each lab, such as this one, will thus be written with __Rmarkdown__ a light markdown language in which one mixes code and explaination. This allows to easily comment and describe our experiments in the same document than the one containing the code. This also helps to be sure that your code is self sufficient by requiring the document to _compiles_ on its own.



# Exploratory Data Analysis (EDA).

The dataset used by Galton is available in __R__ in the package __HistData__ which contains several datasets of historical interests. Packages are the extension of __R__ that are made available in the easy to use format by its users. The first step for you is to install this package. You only have to do it once as the packages are stored locally. You can either use the _Packages_ tab of the lower right panel in __Rstudio__ or the command line
```{r, eval = FALSE}
install.packages("HistData")
```




We are now ready to look at the dataset: we should _load_ first the package with the `library` command, which allows use to look at the first lines of the dataset __GastonFamilies__ with the __head__ command.

```{r Head}
library(HistData)
head(GaltonFamilies)

```

It is organized in a table, called a dataframe in __R__, in which each column may have a different type. Using the `glimpse` command of the package __dplyr__ (that you should install), we may see what is in this dataframe.

```{r Glimpse}
library(dplyr)
glimpse(GaltonFamilies)
```

You can have more information by using __help__:
```{r Help, eval = FALSE}
help(GaltonFamilies)
```


We have thus 934 observation of 8 variables:

- __family__, a _factor_ giving a identifier for each family
- __father__, a __double__ giving the height of the father
- __mother__, a __double__ giving the height of the mother
- __midparentHeight__, a __double__ given by the average of the size of the father and the one of the mother multiplies by $1.08$.
- __children__, an __integer__ specifying the number of children within the family
- __childNum__, an __integer__ specifying the rank of the child within the family
- __gender__, a __factor__ giving the sex of the child
- __childHeight__, a __double__ giving the heigth of the child

The types of the column are explicit, except maybe for the __factor__ one. It corresponds to a qualitative variable which has several modalities. The other type of column you may easily encounter are __ordered factor__, __date__, __characters__, which are pretty much self explaining.

Note that the height has been corrected for the sex in the __midparentHeight__ but not in the __childHeight__. We may easily create a new column (variable) __childHeightC__ which apply the same $1.08$ factor to the female. We will rely on the `mutate` command of __dplyr__ that allows to modify or create columns in a convenient way.

```{r Mutate}
GaltonFamilies <- mutate(GaltonFamilies,
                         childHeightC = if_else(gender == "male", childHeight,
                                                1.08 * childHeight))
glimpse(GaltonFamilies)
```

Note that `<-` is the prefered assignment operator in __R__ (`=` would also work here).

We are now ready to visualize this dataset using the __ggplot2__ package (that you should install first). This package allows to produce nice plot with a quite explicit syntax.

```{r Ggplot2}
library(ggplot2)
ggplot(data = GaltonFamilies, aes(x = midparentHeight, y = childHeightC)) + geom_point()
```

This representation can be enhanced by adding some transparency to the point so that we can visualize if several child with the same height have the same parent height.

```{r Alpha}
ggplot(data = GaltonFamilies, aes(x = midparentHeight, y = childHeightC)) + geom_point(alpha = .125)
```

If we are interested in the height increment, we can either compute this new variable on the fly or add it explicitely.

```{r Increment}
ggplot(data = GaltonFamilies, aes(x = midparentHeight, y = childHeightC - midparentHeight)) + geom_point(alpha = .125)

GaltonFamilies <- mutate(GaltonFamilies, incrementHeight = childHeightC - midparentHeight)
ggplot(data = GaltonFamilies, aes(x = midparentHeight, y = incrementHeight)) + geom_point(alpha = .125)

```


# Performing a linear regression

The __R__ command `lm` performs a linear regression specified by a _formula_ explaining which variable(s) to use and a _dataset_.

For instance,
```{r Reg}
reg <- lm(childHeightC ~ midparentHeight, data = GaltonFamilies)
```
computes the linear regression of __childHeightC__ with respect to __midparentHeight__.

We can see the coefficients by calling directly `reg`.
```{r Reg2}
reg
```

__R__ automatically computes the variances of each parameters (as well as much more quantities that we will study later). They are available with the __summary__ command:
```{r Summary}
summary(reg)
```

This gives the estimated values (__estimate__) of the intercept and the slope called respectively __(Intercept)__ and __midparentHeight__ as well their estimated standard deviations.


We can also use __ggplot2__ to visualize the regression. Note that the linear regression is recomputed on the fly here.
```{r VisReg}
ggplot(data = GaltonFamilies, aes(x = midparentHeight, y = childHeightC)) +
  geom_point(alpha = .125) + geom_smooth(method = "lm")
```



## Exercises

1. Compute the regression of the __incrementHeight__ with respect to the __midparentHeight__. How does this results compare to the one obtained previously.

```{r}
reg <- lm(incrementHeight ~ midparentHeight, data = GaltonFamilies)
summary(reg)
coefficients(reg)
```


2. Simulation Problem.
      a. Generate $n = 100$ data as follows. Take $X_i \sim \mathrm{Unif}([0,1])$. Then set
$$
Y_i = \beta_0 + \beta_1 X_i+ \epsilon_i,\quad i=1,\ldots,n,
$$
where $\beta_0 = 4$ and $\beta_1 = 2$ and $\epsilon_i \sim N(0,1)$. Plot the data. Fit the regression line. Add the fitted line to the plot.

```{r}

beta_0=4
beta_1=2
e=rnorm(100,0,1)
x=runif(n,min=0,max=1)
y=beta_0+beta_1*x+e

reg<-lm(y~x)

ggplot(data=data.frame(x,y),aes(x=x,y=y))+geom_point(alpha=1)+geom_smooth(method=lm)
reg$coefficients[2]
```

   b. Repeat the experiment in (a) 1,000 times. You will get a different value of $\widehat\beta_1$ each time. Denote these by $\widehat{\beta}_1^{(1)},\ldots,\widehat{\beta}_1^{(1000)}$. What is the mean of these values? What value do you expect the mean to be? Plot a histogram of $\widehat\beta_1^{(1)},\ldots,\widehat\beta_1^{(1000)}$.

```{r}
beta=2
for (j in c(1:1000))
{x=runif(100,0,1)
y=4+2*x+rnorm(100,0,1)
reg2=lm(y~x)
beta[j]=reg2$coeff[2]}
hist(beta)
```


   c. Repeat (b) but now take $\epsilon_i$ to have a Cauchy distribution. How does the histogram change?
   
```{r}
beta=2
for (j in c(1:1000))
{x=runif(100,0,1)
y=4+2*x+rcauchy(100,0,1)
reg2=lm(y~x)
beta[j]=reg2$coeff[2]}
hist(beta)
```
   
   
3. Load the dataset __airquality__ using the R command: __data(airquality)__.

    a. Use the summary command to summarize the data. Use the pairs command to
plot scatterplots of all pairs of data.

```{r}
data("airquality")
summary(airquality)
pairs(airquality)
```


    b. Plot __Ozone__ versus __Solar Radiation__. (Put __Solar__ on the $x$-axis.) Describe the rela-
tionship between these variables.
```{r}

```


    c. Fit a least squares regression line. Add the line to the plot and report the intercept
and slope.

    d. Compute the residuals $\epsilon_i = Y_i - (\widehat{\beta}_0 + \widehat{\beta}_1 X_i)$. Plot the residuals versus the $X_i$'s.
Does it appear that the standard linear regression model assumptions hold?
